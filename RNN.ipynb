{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "Andrej Karpathy blog: The Unreasonable Effectiveness of Recurrent Neural Networks http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "Stanford cs231n (spring 2017) lecture 10: Recurrent Neural Networks https://www.youtube.com/watch?v=6niqTuYFZLQ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context:\n",
    "\n",
    "Neural networks like CNNs typically require some fixed-size input and produce a fixed-size output. \n",
    "\n",
    "RNNs can operate on every item of a sequence; so the length of that sequence can very in size. Not just the input, the output can also vary in size.\n",
    "\n",
    "This has several advantages: you can have various combo of input size vs output size.\n",
    "\n",
    "You can also iterate over fixed-sized inputs on an RNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./img/rnn-in-out-size.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does a RNN work?\n",
    "\n",
    "Like a static variable in a class that gets updated every time some method is called, a hidden state in a RNN cell retains some of the things it has seen, and is updated by new inputs.\n",
    "\n",
    "The __Recurrent__ part of RNN:\n",
    "\n",
    "For example: for every word in a sentence, run the word through the RNN function. The input word can be a one-hot encoded vector:\n",
    "\n",
    "$$h_t = \\tanh ( W_{hh} h_{t-1} + W_{xh} x_t )$$\n",
    "\n",
    "At the first step ($t = 1$), the function takes the first word $x_1$, and a hidden state $h$ as inputs. Since the hidden state is initialized to a vector of zeroes, the first hidden state is essentially the tanh of the first word:\n",
    "\n",
    "$$h_1 = \\tanh ( W_{xh} x_1 )$$\n",
    "\n",
    "\n",
    "The second word $x_2$ together with previous step's hidden state $h_1$ are fed into the same function to produce a new hidden state $h_2$:\n",
    "\n",
    "$$h_2 = \\tanh ( W_{hh} h_1 + W_{xh} x_2 )$$\n",
    "\n",
    "This process is repeated until the end of the sentence.\n",
    "\n",
    "Both $x_t$ and $h_t$ have their own set of weights $W_{xh}$ and $W_{hh}$ (as a fully connected layer) that remain unchanged during the forward pass.\n",
    "\n",
    "If you want to produce an output $y_t$ at each step, you can introduce another set of weights $W_{hy}$ for the calculation:\n",
    "\n",
    "$$y_t = W_{hy} h_t $$\n",
    "\n",
    "The last hidden state $y_T$ at the end of the sentence can be considered to be a summary of the input sentence.\n",
    "\n",
    "As a program, it looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    '''A single recurrent cell'''\n",
    "    def step(self, x):\n",
    "        '''Update the hidden state'''\n",
    "        self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x))\n",
    "        # Optional: compute the output vector\n",
    "        y = np.dot(self.W_hy, self.h)\n",
    "        return y\n",
    "\n",
    "rnn = RNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: `np.dot(a, b)` is the dot-product of 2 matrices (matrix or vector multiplication with a summation).\n",
    "\n",
    "Notice that there are __three sets of weights__! One (`W_hh`) for the hidden state; one (`W_xh`) for the input; and one (`W_hy`) for the output.\n",
    "\n",
    "The hidden state `self.h` is initialized with a zero vector.\n",
    "\n",
    "`np.tanh` function implements a non-linearity that squashes the activations to the range `[-1, 1]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each step in a sequence, you'd run the line below to update the hidden state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.step(x) # x is an input vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
