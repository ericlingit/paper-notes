{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to understand what transformers are by reading its paper [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf).\n",
    "\n",
    "https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./img/attn-abstract-seq-transduction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is __sequence transduction__?\n",
    "\n",
    "Transduction: translation of energy from one form into another. eg, your nerve cells sense heat energy, and fire off electrical signals, so that your brain can feel heat. in this case, your nerve cells are a transducer. Another example is a microphone's magnet converting sound wave (vibrations) into electrical signals. It's an interpretation of a signal, sometimes converted into a form that can be understood and processed by something like a brain. Note that the energy itself is not converted into another form of energy.\n",
    "\n",
    "Induction: derive a function from given data\n",
    "\n",
    "Deduction: plug numbers into the function to make predictions\n",
    "\n",
    "Transductive Learning: get predictions directly from given data (no approximation function needed). Example: k-nearest algorithm. It does not model the training data, but uses it directly each time a prediction is required.\n",
    "\n",
    "In NLP, a transducer is a model that outputs one time-step (word) for each input time-step (word) provided (ie, an output is produced for each input it reads in; and only ONE output for each input; aka finite-state transducer).\n",
    "\n",
    "Transduction is a synonym for transformation: Many machine learning tasks can be expressed as the transformation (transduction) of input sequences into output sequences.\n",
    "\n",
    "__Sequence transduction__: the transformation (transduction) of input sequences into output sequences. eg, turning sound waves into words (speech recognition); turning one sequence of words in one language, into another language (machine translation).\n",
    "\n",
    "\n",
    "Source: https://machinelearningmastery.com/transduction-in-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why call it a \"time-step\", and not something more concrete like \"word\"?\n",
    "\n",
    "Because the inputs are not always a sequence of words. It could be a sequence of images (like a video). Since words uttered, and frames played are ordered from earlier to later, each word or frame is a step forward or backward in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note to self\n",
    "\n",
    "transformers have something to do with RNNs\n",
    "\n",
    "and I have a poor understanding of what RNNs are\n",
    "\n",
    "figure RNNs out before continuing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- discards RNN and CNN altogether\n",
    "- the problem with rnns is that it runs sequentially. this makes it hard to parallelize while training.\n",
    "- since attention mechanisms allow you to not worry about the distance between input words, you don't need recurrence to feed inputs sequentially.\n",
    "- transformer relies exclusively on attention to figure out the relationship between input & output, this allows parallelization to boost the performance.\n",
    "- transformer also has an encoder-decoder structure\n",
    "- transformer has residual connections!!!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
