{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Machine Translation by Jointly Learning to Align and Translate https://arxiv.org/abs/1409.0473\n",
    "\n",
    "Attention? Attention! https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you first look at an image, you first focus on one spot before moving to another spot. This wandering focus is your attention: it spotlights the things that matter, and ignores the things that don't.\n",
    "\n",
    "Just as you can divide an image into sections (spots), and selectively process on just a few of them, you can do the same thing with words, where each word token is its own section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides scanning from spot to spot on an image, your mind also 'expects' (predicts) what it'll see next based on the things it has already seen. For example, when you see a furry texture with a snout, your mind expects to see an animal.\n",
    "\n",
    "With words, if you read 'she is eating a ...', you'd expect that whatever follows is a food of some sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So attention is not just the focus on where to look, but also how the item you're looking at change your expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a new context vector is generated by the decoder before it generates an output. the context vector is calculated from the annotations and the annotation weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when the decoder is trying to generate an output $y_t$, it needs to first figure out which input word to look at. This is done by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The paper](https://arxiv.org/abs/1409.0473)\n",
    "\n",
    "divide the input image into grids\n",
    "\n",
    "use a weight to decide which block to look at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can do the same to a rnn for words:\n",
    "\n",
    "retain all the hidden states, and stack them into a matrix\n",
    "\n",
    "apply a weight to select which hidden state to look at when the decoder is generating a translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the input sentence is run twice: once forwrad, once backward into the rnn. the hidden states of each run are collected and lined up according to the order of the words. \n",
    "\n",
    "now for each word in the sentence, you have 2 hidden states: one that remembers the words before it, and the other remembers the words that come after it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The run from the first word $x_1$ to the last word $x_T$ to calculate the forward hidden states:\n",
    "\n",
    "$(\\overrightarrow{h_1}, \\dots, \\overrightarrow{h_{T_x}})$\n",
    "\n",
    "The backward run from the last word $x_T$ to the first word $x_1$ to calculate the backward hidden states:\n",
    "\n",
    "$(\\overrightarrow{h_{T_x}}, \\dots, \\overrightarrow{h_1})$\n",
    "\n",
    "This backward hidden states vector is reversed so that the inputs $x_t$ are aligned with the forward hidden states vector:\n",
    "\n",
    "$(\\overleftarrow{h_1}, \\dots, \\overleftarrow{h_{T_x}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the forward and backward hidden states for each input word are stacked (concatenated) together to form its __annotation__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The annotation $h_j$ contains the forward and backward hidden states at each step:\n",
    "\n",
    "$h_j = \\left[\n",
    "\\overrightarrow{h}_j^\\top ; \\overleftarrow{h}_j^\\top \\right]^\\top$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since RNNs only retain recent knowledge, the annotation will have both the preceding word, and the following words.\n",
    "\n",
    "This __annotation__ is what gets used later to calculate the context vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context vector $c_t$ is the weighted sum of the annotations\n",
    "\n",
    "It's the 'summary' of annotations (from the encoder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### self-attention == association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
