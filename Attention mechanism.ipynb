{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Machine Translation by Jointly Learning to Align and Translate https://arxiv.org/abs/1409.0473 (the attention paper)\n",
    "\n",
    "Attention? Attention! https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html\n",
    "\n",
    "Effective Approaches to Attention-based Neural Machine Translation https://arxiv.org/pdf/1508.04025.pdf (global attention vs local attention; ie, looking at all words vs looking at some words)\n",
    "\n",
    "Show, Attend and Tell: Neural Image CaptionGeneration with Visual Attention http://proceedings.mlr.press/v37/xuc15.pdf (attention for image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELI5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you first look at an image, you first focus on one spot before moving to another spot. This wandering focus is your attention: it spotlights the things that matter, and ignores the things that don't.\n",
    "\n",
    "Just as you can divide an image into sections (spots), and selectively process on just a few of them, you can do the same thing with words, where each word token is its own section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides scanning from spot to spot on an image, your mind also 'expects' (predicts) what it'll see next based on the things it has already seen. For example, when you see a furry texture with a snout, your mind expects to see an animal.\n",
    "\n",
    "With words, if you read 'she is eating a ...', you'd expect that whatever follows is a food of some sort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So attention is not just the focus on where to look, but also how the item you're looking at change your expectation because things in a scene can relate to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do the same to a RNN encoder-decoder model for words:\n",
    "\n",
    "Retain all the hidden states, and stack them into a matrix\n",
    "\n",
    "Apply a weight to select which hidden state to look at when the decoder is generating a translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input sentence is run twice: once forwrad, once backward into the encoder. The hidden states of each run are collected and lined up according to the order of the sentence.\n",
    "\n",
    "Now, each word in the sentence has 2 hidden states: one that remembers the words before it, and the other remembers the words that come after it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The run from the first word $x_1$ to the last word $x_T$ to calculate the forward hidden states:\n",
    "\n",
    "$$(\\overrightarrow{h_1}, \\dots, \\overrightarrow{h_{T_x}})$$\n",
    "\n",
    "The backward run from the last word $x_T$ to the first word $x_1$ to calculate the backward hidden states:\n",
    "\n",
    "$$(\\overrightarrow{h_{T_x}}, \\dots, \\overrightarrow{h_1})$$\n",
    "\n",
    "This backward hidden states vector is reversed so that the order of inputs $x_t$ are aligned with the forward hidden states vector:\n",
    "\n",
    "$$(\\overleftarrow{h_1}, \\dots, \\overleftarrow{h_{T_x}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bidirectional hidden states for each input word are stacked (concatenated) together to form __annotation__ $h_j$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h_j = \\left[\n",
    "\\overrightarrow{h}_j^\\top ; \\overleftarrow{h}_j^\\top \\right]^\\top$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since RNNs only retain recent knowledge, the bidirectional hidden states at each step will have information for both the preceding words, and the following words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The decoder\n",
    "\n",
    "The decoder decides parts of the source sentence to pay attention to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find which words (annotations) to pay attention to, we need some sort of mask to highlight certain words, and diminish others before the decoder can decide on an output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mask is the context vector $c_i$ (aka, the attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$c_i = \\sum_{j=1}^{T_x} \\alpha_{ij} h_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context vector __for the current step__ $c_i$ is the sum of the current step's alignment weight $a_{ij}$ multiplied by __all annotations__ $h_j$.\n",
    "\n",
    "_Alignment_ means matching the input word (annotation) to the output word. The alignment is based on the decoder's previous hidden state $s_{i-1}$ and the annotations $h_j$.\n",
    "\n",
    "__$a_{ij}$ is the weights that select which words to pay attention to by highlighting some words, and diminishing others__.\n",
    "\n",
    "$a_{ij}$ is the probability that output $y_i$ is aligned to the source word $x_j$.\n",
    "\n",
    "For each output $y_i$, an annotation weight $a_{ij}$ is generated for every word $x_{j}$ of the source sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the decoder has the context vector, it can go on to calculate the new hidden state $s_i$ and an output $y_i$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$s_i = f(s_{i-1}, y_{i-1}, c_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y_i = g(s_i, y_{i-1}, c_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Before the decoder generates an output $y_t$, it needs to figure out which input word to look at. So the decoder calculates a context vector $c_i$ to decide which words to look at. Once it has a context vector, the decoder can take the previous input, and the previous step's hidden state, and the context vector to produce a new output $y_t$.~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "\n",
    "I still don't fully understand how the annotation weight $a_{ij}$ is calculated. The paper lists these 2 equations which I still can't parse in my head (in plain language), so I'll leave them here and update my notes later when I finally figure them out.\n",
    "\n",
    "Copied verbatim from the paper:\n",
    "\n",
    "$$\\alpha_{ij} = \\frac{\\exp\\left(e_{ij}\\right)}{\\sum_{k=1}^{T_x} \\exp\\left(e_{ik}\\right)}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$e_{ij} = a(s_{i-1}, h_j)$$\n",
    "\n",
    "is an _alignment model_ which scores how well the inputs around position $j$ and the output at position $i$ match. The score is based on the decoder's last hidden state $s_{i-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Show, Attend and Tell: Neural Image CaptionGeneration with Visual Attention](http://proceedings.mlr.press/v37/xuc15.pdf) by Xu et, al:\n",
    "\n",
    "For each location $i$, the attention mechanism generates a positive weight $\\alpha_i$ which can be interpreted either as the probability that location $i$ is the right place to focus for producing the next word, or as the relative importance to give to each location.\n",
    "\n",
    "The weight $\\alpha_i$ of each annotation vector $a_i$ is computed by an attention model $f_{att}$ for which we use a multilayer perceptron conditioned on the previous hidden state $h_{tâˆ’1}$. To emphasize, we note that the hidden state varies as the output RNN advances in its output sequence: \"where\" the network looks next depends on the sequence of words that has already been generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other forms of attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### self-attention: association/correlation between the current word and the previous parts of the sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
